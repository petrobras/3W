{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be897dda",
   "metadata": {},
   "source": [
    "# ğŸ“š Unsupervised Learning and Novelty Detection (5 minutes)\n",
    "\n",
    "### What is Unsupervised Learning?\n",
    "\n",
    "**Unsupervised Learning** is a machine learning approach where we analyze data without labeled examples, seeking to discover hidden patterns, structures, or anomalies in the data.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Unlabeled Data**: Input data without target labels\n",
    "2. **Pattern Discovery**: Finding hidden structures in data\n",
    "3. **Anomaly Detection**: Identifying unusual or outlier patterns\n",
    "4. **Dimensionality Reduction**: Learning compact representations\n",
    "5. **Reconstruction**: Learning to recreate input data\n",
    "\n",
    "### Our Novelty Detection Problem: 3W Oil Well Anomaly Detection\n",
    "\n",
    "- **Objective**: Detect abnormal oil well operational states using only normal operation data\n",
    "- **Training Data**: Only class 0 (normal operation) sensor measurements\n",
    "- **Detection Target**: Identify when sensor patterns deviate from normal behavior\n",
    "- **Challenge**: Learn normal patterns to detect any deviation as potential fault\n",
    "\n",
    "### Why Novelty Detection Matters in Oil Wells:\n",
    "- **Early Warning System**: Detect problems before they escalate\n",
    "- **Unsupervised Monitoring**: No need for labeled fault examples\n",
    "- **Operational Safety**: Continuous monitoring of normal vs abnormal states\n",
    "- **Preventive Maintenance**: Identify subtle deviations before major failures\n",
    "\n",
    "### Autoencoder-Based Novelty Detection Approach:\n",
    "- **Training Phase**: Learn to reconstruct only normal operation patterns (class 0)\n",
    "- **Detection Phase**: High reconstruction error indicates potential anomaly\n",
    "- **Threshold**: Statistical approach (mean + 3Ã—std) for anomaly scoring\n",
    "- **Evaluation**: Test how well it distinguishes normal vs fault classes\n",
    "\n",
    "### Problem Characteristics:\n",
    "- **Normal-Only Training**: Learn patterns from class 0 data exclusively\n",
    "- **Time Series**: Sequential sensor measurements requiring LSTM architecture\n",
    "- **High Dimensional**: Many sensors Ã— time steps = complex patterns\n",
    "- **Reconstruction-Based**: Anomalies have higher reconstruction errors\n",
    "- **Threshold-Based**: Statistical approach for anomaly detection\n",
    "\n",
    "Let's explore LSTM autoencoders for oil well novelty detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce29f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Optimized Loading: 3W Dataset for Autoencoder Novelty Detection\n",
      "======================================================================\n",
      "ğŸ“¦ Importing modules... âœ…\n",
      "âš™ï¸ Optimization Settings:\n",
      "   â€¢ Single fold loading: True\n",
      "   â€¢ Target fold: fold_1\n",
      "   â€¢ Sampling enabled: True\n",
      "   â€¢ Max normal samples: 2000\n",
      "   â€¢ Max anomaly samples: 1000\n",
      "\n",
      "ğŸ“‚ Initializing data persistence... âœ…\n",
      "âš¡ Using format: pickle for maximum speed\n",
      "ğŸ“ Checking windowed directory: processed_data\\cv_splits\\windowed... âœ…\n",
      "ğŸ” Looking for fold directories... âœ… Found 3 folds: ['fold_1', 'fold_2', 'fold_3']\n",
      "ğŸ¯ Using single fold: fold_1 for fast loading\n",
      "\n",
      "ğŸ“ Processing fold_1 (1/1)...\n",
      "   ğŸ“„ Loading train data... âœ…\n",
      "âš™ï¸ Optimization Settings:\n",
      "   â€¢ Single fold loading: True\n",
      "   â€¢ Target fold: fold_1\n",
      "   â€¢ Sampling enabled: True\n",
      "   â€¢ Max normal samples: 2000\n",
      "   â€¢ Max anomaly samples: 1000\n",
      "\n",
      "ğŸ“‚ Initializing data persistence... âœ…\n",
      "âš¡ Using format: pickle for maximum speed\n",
      "ğŸ“ Checking windowed directory: processed_data\\cv_splits\\windowed... âœ…\n",
      "ğŸ” Looking for fold directories... âœ… Found 3 folds: ['fold_1', 'fold_2', 'fold_3']\n",
      "ğŸ¯ Using single fold: fold_1 for fast loading\n",
      "\n",
      "ğŸ“ Processing fold_1 (1/1)...\n",
      "   ğŸ“„ Loading train data... âœ… (176367 windows)\n",
      "      ğŸ“Š Current totals: 2000 normal, 1000 anomaly\n",
      "      ğŸ¯ Sampling limits reached - stopping early\n",
      "   ğŸ¯ Sampling complete - sufficient data collected\n",
      "\n",
      "âœ… Successfully loaded and separated windowed data!\n",
      "ğŸ’š Normal operation windows (class 0): 2000\n",
      "ğŸ”´ Anomaly windows (classes 1-9): 1000\n",
      "âš¡ Loading time: 12.157 seconds\n",
      "ğŸ“ Files processed: 1\n",
      "\n",
      "ğŸ“‹ Processing sample windows... âœ…\n",
      "\n",
      "ğŸªŸ Sample Normal Window (Window #1):\n",
      "   â€¢ Shape: (300, 3)\n",
      "   â€¢ Class: 0 (Normal Operation)\n",
      "   â€¢ Features: ['P-TPT_scaled', 'T-TPT_scaled', 'class']\n",
      "\n",
      "ğŸ“Š Normal Operation Data (Class 0):\n",
      "   â€¢ Total windows: 2000\n",
      "   â€¢ Will be used for: Autoencoder training\n",
      "\n",
      "ğŸ“Š Anomaly Data (Classes 1-9):\n",
      "   â€¢ Class 1: 513 windows\n",
      "   â€¢ Class 2: 371 windows\n",
      "   â€¢ Class 3: 116 windows\n",
      "   â€¢ Total anomaly windows: 1000\n",
      "   â€¢ Will be used for: Anomaly detection testing\n",
      "\n",
      "âš¡ Performance Summary:\n",
      "   â€¢ Total execution time: 14.168 seconds\n",
      "   â€¢ Data loading time: 12.157 seconds\n",
      "   â€¢ File format: pickle\n",
      "   â€¢ Folds processed: 1\n",
      "   â€¢ Speed improvement: ~3.0x faster than full loading\n",
      "\n",
      "ğŸ¯ Dataset Summary for Novelty Detection:\n",
      "   â€¢ Normal training data: 2000 windows\n",
      "   â€¢ Anomaly test data: 1000 windows\n",
      "   â€¢ Window dimensions: (300, 3)\n",
      "   â€¢ Anomaly classes: [np.str_('1'), np.str_('2'), np.str_('3')]\n",
      "   â€¢ Ready for: LSTM Autoencoder training and novelty detection\n",
      "\n",
      "ğŸ’¡ Optimization Notes:\n",
      "   â€¢ Sampling enabled for faster processing\n",
      "   â€¢ To use full dataset: Set ENABLE_SAMPLING = False\n",
      "   â€¢ To use all folds: Set USE_SINGLE_FOLD = False\n",
      "âœ… (176367 windows)\n",
      "      ğŸ“Š Current totals: 2000 normal, 1000 anomaly\n",
      "      ğŸ¯ Sampling limits reached - stopping early\n",
      "   ğŸ¯ Sampling complete - sufficient data collected\n",
      "\n",
      "âœ… Successfully loaded and separated windowed data!\n",
      "ğŸ’š Normal operation windows (class 0): 2000\n",
      "ğŸ”´ Anomaly windows (classes 1-9): 1000\n",
      "âš¡ Loading time: 12.157 seconds\n",
      "ğŸ“ Files processed: 1\n",
      "\n",
      "ğŸ“‹ Processing sample windows... âœ…\n",
      "\n",
      "ğŸªŸ Sample Normal Window (Window #1):\n",
      "   â€¢ Shape: (300, 3)\n",
      "   â€¢ Class: 0 (Normal Operation)\n",
      "   â€¢ Features: ['P-TPT_scaled', 'T-TPT_scaled', 'class']\n",
      "\n",
      "ğŸ“Š Normal Operation Data (Class 0):\n",
      "   â€¢ Total windows: 2000\n",
      "   â€¢ Will be used for: Autoencoder training\n",
      "\n",
      "ğŸ“Š Anomaly Data (Classes 1-9):\n",
      "   â€¢ Class 1: 513 windows\n",
      "   â€¢ Class 2: 371 windows\n",
      "   â€¢ Class 3: 116 windows\n",
      "   â€¢ Total anomaly windows: 1000\n",
      "   â€¢ Will be used for: Anomaly detection testing\n",
      "\n",
      "âš¡ Performance Summary:\n",
      "   â€¢ Total execution time: 14.168 seconds\n",
      "   â€¢ Data loading time: 12.157 seconds\n",
      "   â€¢ File format: pickle\n",
      "   â€¢ Folds processed: 1\n",
      "   â€¢ Speed improvement: ~3.0x faster than full loading\n",
      "\n",
      "ğŸ¯ Dataset Summary for Novelty Detection:\n",
      "   â€¢ Normal training data: 2000 windows\n",
      "   â€¢ Anomaly test data: 1000 windows\n",
      "   â€¢ Window dimensions: (300, 3)\n",
      "   â€¢ Anomaly classes: [np.str_('1'), np.str_('2'), np.str_('3')]\n",
      "   â€¢ Ready for: LSTM Autoencoder training and novelty detection\n",
      "\n",
      "ğŸ’¡ Optimization Notes:\n",
      "   â€¢ Sampling enabled for faster processing\n",
      "   â€¢ To use full dataset: Set ENABLE_SAMPLING = False\n",
      "   â€¢ To use all folds: Set USE_SINGLE_FOLD = False\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# OPTIMIZED LOADING: 3W DATASET FOR UNSUPERVISED NOVELTY DETECTION\n",
    "# ============================================================\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"ğŸ¤– Optimized Loading: 3W Dataset for Autoencoder Novelty Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Import data loading utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "print(\"ğŸ“¦ Importing modules...\", end=\" \")\n",
    "from src.data_persistence import DataPersistence\n",
    "from src import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ…\")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIMIZATION SETTINGS - ADJUST FOR SPEED vs COMPLETENESS\n",
    "# ============================================================\n",
    "USE_SINGLE_FOLD = (\n",
    "    True  # True: Fast loading (one fold), False: Complete dataset (all folds)\n",
    ")\n",
    "TARGET_FOLD = \"fold_1\"  # Which fold to use for single fold loading\n",
    "MAX_NORMAL_SAMPLES = 2000  # Limit normal samples for faster processing\n",
    "MAX_ANOMALY_SAMPLES = 1000  # Limit anomaly samples for faster processing\n",
    "ENABLE_SAMPLING = True  # True: Apply sampling limits, False: Load all available data\n",
    "\n",
    "print(f\"âš™ï¸ Optimization Settings:\")\n",
    "print(f\"   â€¢ Single fold loading: {USE_SINGLE_FOLD}\")\n",
    "if USE_SINGLE_FOLD:\n",
    "    print(f\"   â€¢ Target fold: {TARGET_FOLD}\")\n",
    "print(f\"   â€¢ Sampling enabled: {ENABLE_SAMPLING}\")\n",
    "if ENABLE_SAMPLING:\n",
    "    print(f\"   â€¢ Max normal samples: {MAX_NORMAL_SAMPLES}\")\n",
    "    print(f\"   â€¢ Max anomaly samples: {MAX_ANOMALY_SAMPLES}\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nğŸ“‚ Initializing data persistence...\", end=\" \")\n",
    "    persistence = DataPersistence(base_dir=config.PROCESSED_DATA_DIR, verbose=False)\n",
    "    print(\"âœ…\")\n",
    "\n",
    "    print(f\"âš¡ Using format: {config.SAVE_FORMAT} for maximum speed\")\n",
    "\n",
    "    # Check if windowed directory exists\n",
    "    windowed_dir = os.path.join(persistence.cv_splits_dir, \"windowed\")\n",
    "    print(f\"ğŸ“ Checking windowed directory: {windowed_dir}...\", end=\" \")\n",
    "\n",
    "    if not os.path.exists(windowed_dir):\n",
    "        print(\"âŒ\")\n",
    "        print(\n",
    "            \"âŒ No windowed data directory found. Please run Data Treatment notebook first to generate windowed time series data.\"\n",
    "        )\n",
    "        raise FileNotFoundError(\"Windowed data directory not found\")\n",
    "    else:\n",
    "        print(\"âœ…\")\n",
    "\n",
    "        # Look for fold directories\n",
    "        print(\"ğŸ” Looking for fold directories...\", end=\" \")\n",
    "        fold_dirs = [\n",
    "            d\n",
    "            for d in os.listdir(windowed_dir)\n",
    "            if d.startswith(\"fold_\") and os.path.isdir(os.path.join(windowed_dir, d))\n",
    "        ]\n",
    "        fold_dirs.sort()\n",
    "        print(f\"âœ… Found {len(fold_dirs)} folds: {fold_dirs}\")\n",
    "\n",
    "        if not fold_dirs:\n",
    "            print(\"âŒ No fold directories found in windowed data.\")\n",
    "            raise FileNotFoundError(\"No fold directories found\")\n",
    "\n",
    "        # Determine which folds to process\n",
    "        if USE_SINGLE_FOLD:\n",
    "            if TARGET_FOLD in fold_dirs:\n",
    "                process_folds = [TARGET_FOLD]\n",
    "                print(f\"ğŸ¯ Using single fold: {TARGET_FOLD} for fast loading\")\n",
    "            else:\n",
    "                process_folds = [fold_dirs[0]]  # Use first available fold\n",
    "                print(\n",
    "                    f\"âš ï¸ Target fold '{TARGET_FOLD}' not found, using: {process_folds[0]}\"\n",
    "                )\n",
    "        else:\n",
    "            process_folds = fold_dirs\n",
    "            print(f\"ğŸ“Š Using all {len(fold_dirs)} folds for complete dataset\")\n",
    "\n",
    "        # Separate data containers for normal (class 0) and anomaly (classes 1-9) data\n",
    "        normal_windows = []  # Class 0 for autoencoder training\n",
    "        normal_classes = []\n",
    "        anomaly_windows = []  # Classes 1-9 for anomaly testing\n",
    "        anomaly_classes = []\n",
    "\n",
    "        load_start = time.time()\n",
    "        total_files_processed = 0\n",
    "\n",
    "        for fold_idx, fold_name in enumerate(process_folds):\n",
    "            fold_path = os.path.join(windowed_dir, fold_name)\n",
    "\n",
    "            print(\n",
    "                f\"\\nğŸ“ Processing {fold_name} ({fold_idx + 1}/{len(process_folds)})...\"\n",
    "            )\n",
    "\n",
    "            # Process training and test data\n",
    "            for data_type in [\"train\", \"test\"]:\n",
    "                print(f\"   ğŸ“„ Loading {data_type} data...\", end=\" \")\n",
    "\n",
    "                # Try pickle first, then parquet\n",
    "                pickle_file = os.path.join(\n",
    "                    fold_path, f\"{data_type}_windowed.{config.SAVE_FORMAT}\"\n",
    "                )\n",
    "                parquet_file = os.path.join(fold_path, f\"{data_type}_windowed.parquet\")\n",
    "\n",
    "                fold_dfs, fold_classes = [], []\n",
    "\n",
    "                if os.path.exists(pickle_file):\n",
    "                    try:\n",
    "                        fold_dfs, fold_classes = persistence._load_dataframes(\n",
    "                            pickle_file, config.SAVE_FORMAT\n",
    "                        )\n",
    "                        print(f\"âœ… ({len(fold_dfs)} windows)\")\n",
    "                        total_files_processed += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Pickle error: {str(e)}\")\n",
    "                        # Try parquet as fallback\n",
    "                        if os.path.exists(parquet_file):\n",
    "                            try:\n",
    "                                fold_dfs, fold_classes = persistence._load_from_parquet(\n",
    "                                    parquet_file\n",
    "                                )\n",
    "                                print(f\"âœ… Parquet fallback ({len(fold_dfs)} windows)\")\n",
    "                                total_files_processed += 1\n",
    "                            except Exception as e2:\n",
    "                                print(f\"âŒ Parquet fallback failed: {str(e2)}\")\n",
    "\n",
    "                elif os.path.exists(parquet_file):\n",
    "                    try:\n",
    "                        fold_dfs, fold_classes = persistence._load_from_parquet(\n",
    "                            parquet_file\n",
    "                        )\n",
    "                        print(f\"âœ… ({len(fold_dfs)} windows)\")\n",
    "                        total_files_processed += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Parquet error: {str(e)}\")\n",
    "                else:\n",
    "                    print(\"âŒ No data file found\")\n",
    "\n",
    "                # Separate normal (class 0) from anomaly (classes 1-9) data\n",
    "                for df, cls in zip(fold_dfs, fold_classes):\n",
    "                    if str(cls) == \"0\":  # Normal operation\n",
    "                        if (\n",
    "                            not ENABLE_SAMPLING\n",
    "                            or len(normal_windows) < MAX_NORMAL_SAMPLES\n",
    "                        ):\n",
    "                            normal_windows.append(df)\n",
    "                            normal_classes.append(cls)\n",
    "                    else:  # Fault conditions (anomalies)\n",
    "                        if (\n",
    "                            not ENABLE_SAMPLING\n",
    "                            or len(anomaly_windows) < MAX_ANOMALY_SAMPLES\n",
    "                        ):\n",
    "                            anomaly_windows.append(df)\n",
    "                            anomaly_classes.append(cls)\n",
    "\n",
    "                # Show progress\n",
    "                if ENABLE_SAMPLING:\n",
    "                    print(\n",
    "                        f\"      ğŸ“Š Current totals: {len(normal_windows)} normal, {len(anomaly_windows)} anomaly\"\n",
    "                    )\n",
    "                    if (\n",
    "                        len(normal_windows) >= MAX_NORMAL_SAMPLES\n",
    "                        and len(anomaly_windows) >= MAX_ANOMALY_SAMPLES\n",
    "                    ):\n",
    "                        print(f\"      ğŸ¯ Sampling limits reached - stopping early\")\n",
    "                        break\n",
    "\n",
    "            # Early exit if sampling limits reached\n",
    "            if (\n",
    "                ENABLE_SAMPLING\n",
    "                and len(normal_windows) >= MAX_NORMAL_SAMPLES\n",
    "                and len(anomaly_windows) >= MAX_ANOMALY_SAMPLES\n",
    "            ):\n",
    "                print(f\"   ğŸ¯ Sampling complete - sufficient data collected\")\n",
    "                break\n",
    "\n",
    "        load_time = time.time() - load_start\n",
    "\n",
    "        if normal_windows and anomaly_windows:\n",
    "            print(f\"\\nâœ… Successfully loaded and separated windowed data!\")\n",
    "            print(f\"ğŸ’š Normal operation windows (class 0): {len(normal_windows)}\")\n",
    "            print(f\"ğŸ”´ Anomaly windows (classes 1-9): {len(anomaly_windows)}\")\n",
    "            print(f\"âš¡ Loading time: {load_time:.3f} seconds\")\n",
    "            print(f\"ğŸ“ Files processed: {total_files_processed}\")\n",
    "\n",
    "            # Display sample window information\n",
    "            if normal_windows:\n",
    "                print(\"\\nğŸ“‹ Processing sample windows...\", end=\" \")\n",
    "                first_normal_window = normal_windows[0]\n",
    "                print(\"âœ…\")\n",
    "\n",
    "                print(f\"\\nğŸªŸ Sample Normal Window (Window #1):\")\n",
    "                print(f\"   â€¢ Shape: {first_normal_window.shape}\")\n",
    "                print(f\"   â€¢ Class: {normal_classes[0]} (Normal Operation)\")\n",
    "                print(f\"   â€¢ Features: {list(first_normal_window.columns)}\")\n",
    "\n",
    "                # Show class distribution\n",
    "                print(f\"\\nğŸ“Š Normal Operation Data (Class 0):\")\n",
    "                print(f\"   â€¢ Total windows: {len(normal_windows)}\")\n",
    "                print(f\"   â€¢ Will be used for: Autoencoder training\")\n",
    "\n",
    "                print(f\"\\nğŸ“Š Anomaly Data (Classes 1-9):\")\n",
    "                anomaly_unique, anomaly_counts = np.unique(\n",
    "                    anomaly_classes, return_counts=True\n",
    "                )\n",
    "                for cls, count in zip(anomaly_unique, anomaly_counts):\n",
    "                    print(f\"   â€¢ Class {cls}: {count} windows\")\n",
    "                print(f\"   â€¢ Total anomaly windows: {len(anomaly_windows)}\")\n",
    "                print(f\"   â€¢ Will be used for: Anomaly detection testing\")\n",
    "\n",
    "                total_time = time.time() - start_time\n",
    "                print(f\"\\nâš¡ Performance Summary:\")\n",
    "                print(f\"   â€¢ Total execution time: {total_time:.3f} seconds\")\n",
    "                print(f\"   â€¢ Data loading time: {load_time:.3f} seconds\")\n",
    "                print(f\"   â€¢ File format: {config.SAVE_FORMAT}\")\n",
    "                print(f\"   â€¢ Folds processed: {len(process_folds)}\")\n",
    "                print(\n",
    "                    f\"   â€¢ Speed improvement: ~{len(fold_dirs)/len(process_folds):.1f}x faster than full loading\"\n",
    "                )\n",
    "\n",
    "                print(f\"\\nğŸ¯ Dataset Summary for Novelty Detection:\")\n",
    "                print(f\"   â€¢ Normal training data: {len(normal_windows)} windows\")\n",
    "                print(f\"   â€¢ Anomaly test data: {len(anomaly_windows)} windows\")\n",
    "                print(f\"   â€¢ Window dimensions: {first_normal_window.shape}\")\n",
    "                print(f\"   â€¢ Anomaly classes: {sorted(anomaly_unique)}\")\n",
    "                print(\n",
    "                    f\"   â€¢ Ready for: LSTM Autoencoder training and novelty detection\"\n",
    "                )\n",
    "\n",
    "                if ENABLE_SAMPLING:\n",
    "                    print(f\"\\nğŸ’¡ Optimization Notes:\")\n",
    "                    print(f\"   â€¢ Sampling enabled for faster processing\")\n",
    "                    print(f\"   â€¢ To use full dataset: Set ENABLE_SAMPLING = False\")\n",
    "                    print(f\"   â€¢ To use all folds: Set USE_SINGLE_FOLD = False\")\n",
    "\n",
    "            else:\n",
    "                print(\"âš ï¸ No normal operation windows found\")\n",
    "\n",
    "        else:\n",
    "            print(\"âš ï¸ Insufficient data found for novelty detection\")\n",
    "            print(f\"   â€¢ Normal windows: {len(normal_windows)}\")\n",
    "            print(f\"   â€¢ Anomaly windows: {len(anomaly_windows)}\")\n",
    "            normal_windows = []\n",
    "            normal_classes = []\n",
    "            anomaly_windows = []\n",
    "            anomaly_classes = []\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error loading data: {str(e)}\")\n",
    "    print(f\"\\nğŸ’¡ Troubleshooting:\")\n",
    "    print(f\"   1. Make sure 'Data Treatment.ipynb' ran completely\")\n",
    "    print(f\"   2. Check if windowed data was saved successfully\")\n",
    "    print(f\"   3. Verify the processed_data directory exists\")\n",
    "    print(f\"   4. Check if pickle files are corrupted\")\n",
    "    print(f\"   5. Try using parquet format instead\")\n",
    "\n",
    "    # Show detailed error information\n",
    "    import traceback\n",
    "\n",
    "    print(f\"\\nğŸ” Detailed error information:\")\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "    # Initialize empty variables for error case\n",
    "    normal_windows = []\n",
    "    normal_classes = []\n",
    "    anomaly_windows = []\n",
    "    anomaly_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229fa361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Stable LSTM Autoencoder Novelty Detection Implementation\n",
      "=================================================================\n",
      "ğŸ“Š Using stable LSTM Autoencoder for novelty detection...\n",
      "ğŸŸ¢ Normal operation windows for training: 2000\n",
      "ğŸ”´ Anomaly windows for testing: 1000\n",
      "\n",
      "âš¡ Smart Data Sampling for Training Efficiency\n",
      "==================================================\n",
      "ğŸ¯ Training optimization settings:\n",
      "   â€¢ Max normal samples for training: 1000\n",
      "   â€¢ Max anomaly samples for testing: 300\n",
      "   â€¢ Reduced for maximum stability and speed\n",
      "ğŸ“Š Sampling 1000 normal windows from 2000 available...\n",
      "ğŸ“Š Sampling 300 anomaly windows from 1000 available...\n",
      "\n",
      "ğŸ”§ Stable Data Preparation for LSTM Autoencoder\n",
      "==================================================\n",
      "ğŸ“Š Converting normal windows to arrays... 600/1000ğŸ“Š Using stable LSTM Autoencoder for novelty detection...\n",
      "ğŸŸ¢ Normal operation windows for training: 2000\n",
      "ğŸ”´ Anomaly windows for testing: 1000\n",
      "\n",
      "âš¡ Smart Data Sampling for Training Efficiency\n",
      "==================================================\n",
      "ğŸ¯ Training optimization settings:\n",
      "   â€¢ Max normal samples for training: 1000\n",
      "   â€¢ Max anomaly samples for testing: 300\n",
      "   â€¢ Reduced for maximum stability and speed\n",
      "ğŸ“Š Sampling 1000 normal windows from 2000 available...\n",
      "ğŸ“Š Sampling 300 anomaly windows from 1000 available...\n",
      "\n",
      "ğŸ”§ Stable Data Preparation for LSTM Autoencoder\n",
      "==================================================\n",
      "ğŸ“Š Converting normal windows to arrays... âœ… (1000 valid processed)\n",
      "ğŸ“Š Converting anomaly windows to arrays... âœ… (300 valid processed)\n",
      "ğŸ” Validating array shapes and data quality... Expected shape: (300, 2)\n",
      "âœ… Valid arrays: 1000 normal, 300 anomaly\n",
      "ğŸ“Š Data quality checks:\n",
      "   â€¢ Normal data range: [0.000, 1.000]\n",
      "   â€¢ Anomaly data range: [0.000, 1.000]\n",
      "   â€¢ Normal data finite: True\n",
      "   â€¢ Anomaly data finite: True\n",
      "âš¡ Data conversion completed in 0.32 seconds\n",
      "\n",
      "ğŸ“ Data shapes (after removing class column):\n",
      "   â€¢ Normal data: (1000, 300, 2)\n",
      "   â€¢ Anomaly data: (300, 300, 2)\n",
      "\n",
      "ğŸ“‹ LSTM Autoencoder Configuration:\n",
      "   â€¢ Time steps per window: 300\n",
      "   â€¢ Features per time step: 2 (class column removed)\n",
      "   â€¢ Normal training samples: 1000\n",
      "   â€¢ Anomaly test samples: 300\n",
      "\n",
      "ğŸ“Š Additional Data Normalization for Stability\n",
      "=============================================\n",
      "ğŸ“ Enhanced data characteristics:\n",
      "   â€¢ Normal data range: [0.001, 0.999]\n",
      "   â€¢ Anomaly data range: [0.001, 0.999]\n",
      "   â€¢ Data clipped to avoid extreme values\n",
      "   â€¢ Float32 precision for stability\n",
      "\n",
      "ğŸ§  Building Stable LSTM Autoencoder Architecture\n",
      "==================================================\n",
      "ğŸ—ï¸ Stable Architecture Configuration:\n",
      "   â€¢ Input shape: (300, 2)\n",
      "   â€¢ Encoder LSTM units: 32 (conservative for stability)\n",
      "   â€¢ Latent dimension: 16 (conservative for stability)\n",
      "   â€¢ Decoder LSTM units: 32\n",
      "   â€¢ Output shape: (300, 2)\n",
      "   â€¢ Dropout and gradient clipping for regularization\n",
      "ğŸ“Š Converting normal windows to arrays... âœ… (1000 valid processed)\n",
      "ğŸ“Š Converting anomaly windows to arrays... âœ… (300 valid processed)\n",
      "ğŸ” Validating array shapes and data quality... Expected shape: (300, 2)\n",
      "âœ… Valid arrays: 1000 normal, 300 anomaly\n",
      "ğŸ“Š Data quality checks:\n",
      "   â€¢ Normal data range: [0.000, 1.000]\n",
      "   â€¢ Anomaly data range: [0.000, 1.000]\n",
      "   â€¢ Normal data finite: True\n",
      "   â€¢ Anomaly data finite: True\n",
      "âš¡ Data conversion completed in 0.32 seconds\n",
      "\n",
      "ğŸ“ Data shapes (after removing class column):\n",
      "   â€¢ Normal data: (1000, 300, 2)\n",
      "   â€¢ Anomaly data: (300, 300, 2)\n",
      "\n",
      "ğŸ“‹ LSTM Autoencoder Configuration:\n",
      "   â€¢ Time steps per window: 300\n",
      "   â€¢ Features per time step: 2 (class column removed)\n",
      "   â€¢ Normal training samples: 1000\n",
      "   â€¢ Anomaly test samples: 300\n",
      "\n",
      "ğŸ“Š Additional Data Normalization for Stability\n",
      "=============================================\n",
      "ğŸ“ Enhanced data characteristics:\n",
      "   â€¢ Normal data range: [0.001, 0.999]\n",
      "   â€¢ Anomaly data range: [0.001, 0.999]\n",
      "   â€¢ Data clipped to avoid extreme values\n",
      "   â€¢ Float32 precision for stability\n",
      "\n",
      "ğŸ§  Building Stable LSTM Autoencoder Architecture\n",
      "==================================================\n",
      "ğŸ—ï¸ Stable Architecture Configuration:\n",
      "   â€¢ Input shape: (300, 2)\n",
      "   â€¢ Encoder LSTM units: 32 (conservative for stability)\n",
      "   â€¢ Latent dimension: 16 (conservative for stability)\n",
      "   â€¢ Decoder LSTM units: 32\n",
      "   â€¢ Output shape: (300, 2)\n",
      "   â€¢ Dropout and gradient clipping for regularization\n",
      "WARNING:tensorflow:From C:\\Users\\lucas\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucas\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "âœ… Stable LSTM Autoencoder model created\n",
      "\n",
      "ğŸ“‹ Model Summary:\n",
      "   â€¢ Total parameters: 11,346\n",
      "   â€¢ Trainable parameters: 11,346\n",
      "   â€¢ Model architecture optimized for stability\n",
      "   â€¢ Gradient clipping enabled (clipnorm=1.0)\n",
      "   â€¢ Conservative learning rate (0.0005)\n",
      "\n",
      "ğŸš‚ Training Stable LSTM Autoencoder on Normal Data\n",
      "=======================================================\n",
      "ğŸ“Š Training split:\n",
      "   â€¢ Training samples: 800\n",
      "   â€¢ Validation samples: 200\n",
      "ğŸš‚ Starting stable training...\n",
      "   â€¢ Max epochs: 30 (conservative for stability)\n",
      "   â€¢ Batch size: 32 (conservative for stability)\n",
      "   â€¢ Early stopping patience: 10 epochs\n",
      "   â€¢ Learning rate: 0.0005 (conservative)\n",
      "   â€¢ Gradient clipping enabled\n",
      "Epoch 1/30\n",
      "âœ… Stable LSTM Autoencoder model created\n",
      "\n",
      "ğŸ“‹ Model Summary:\n",
      "   â€¢ Total parameters: 11,346\n",
      "   â€¢ Trainable parameters: 11,346\n",
      "   â€¢ Model architecture optimized for stability\n",
      "   â€¢ Gradient clipping enabled (clipnorm=1.0)\n",
      "   â€¢ Conservative learning rate (0.0005)\n",
      "\n",
      "ğŸš‚ Training Stable LSTM Autoencoder on Normal Data\n",
      "=======================================================\n",
      "ğŸ“Š Training split:\n",
      "   â€¢ Training samples: 800\n",
      "   â€¢ Validation samples: 200\n",
      "ğŸš‚ Starting stable training...\n",
      "   â€¢ Max epochs: 30 (conservative for stability)\n",
      "   â€¢ Batch size: 32 (conservative for stability)\n",
      "   â€¢ Early stopping patience: 10 epochs\n",
      "   â€¢ Learning rate: 0.0005 (conservative)\n",
      "   â€¢ Gradient clipping enabled\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0630 - mae: 0.2101 - val_loss: 0.0612 - val_mae: 0.2014 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0630 - mae: 0.2101 - val_loss: 0.0612 - val_mae: 0.2014 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0545 - mae: 0.1902 - val_loss: 0.0452 - val_mae: 0.1686 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0545 - mae: 0.1902 - val_loss: 0.0452 - val_mae: 0.1686 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0397 - mae: 0.1582 - val_loss: 0.0310 - val_mae: 0.1355 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0397 - mae: 0.1582 - val_loss: 0.0310 - val_mae: 0.1355 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0335 - mae: 0.1400 - val_loss: 0.0229 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0335 - mae: 0.1400 - val_loss: 0.0229 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0335 - mae: 0.1361 - val_loss: 0.0221 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0335 - mae: 0.1361 - val_loss: 0.0221 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0292 - mae: 0.1240 - val_loss: 0.0183 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0292 - mae: 0.1240 - val_loss: 0.0183 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0268 - mae: 0.1192 - val_loss: 0.0173 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0268 - mae: 0.1192 - val_loss: 0.0173 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0250 - mae: 0.1147 - val_loss: 0.0164 - val_mae: 0.0973 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0250 - mae: 0.1147 - val_loss: 0.0164 - val_mae: 0.0973 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0263 - mae: 0.1165 - val_loss: 0.0177 - val_mae: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0263 - mae: 0.1165 - val_loss: 0.0177 - val_mae: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0261 - mae: 0.1139 - val_loss: 0.0174 - val_mae: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0261 - mae: 0.1139 - val_loss: 0.0174 - val_mae: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0298 - mae: 0.1188 - val_loss: 0.0172 - val_mae: 0.1002 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0298 - mae: 0.1188 - val_loss: 0.0172 - val_mae: 0.1002 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0272 - mae: 0.1165 - val_loss: 0.0179 - val_mae: 0.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0272 - mae: 0.1165 - val_loss: 0.0179 - val_mae: 0.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0267 - mae: 0.1153\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 0.0169 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 0.0169 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0268 - mae: 0.1144 - val_loss: 0.0178 - val_mae: 0.1061 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0268 - mae: 0.1144 - val_loss: 0.0178 - val_mae: 0.1061 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0277 - mae: 0.1178 - val_loss: 0.0165 - val_mae: 0.0977 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0277 - mae: 0.1178 - val_loss: 0.0165 - val_mae: 0.0977 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0270 - mae: 0.1157 - val_loss: 0.0167 - val_mae: 0.1005 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0270 - mae: 0.1157 - val_loss: 0.0167 - val_mae: 0.1005 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0252 - mae: 0.1118 - val_loss: 0.0171 - val_mae: 0.1025 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0252 - mae: 0.1118 - val_loss: 0.0171 - val_mae: 0.1025 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0244 - mae: 0.1080\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0244 - mae: 0.1082 - val_loss: 0.0164 - val_mae: 0.0989 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0244 - mae: 0.1082 - val_loss: 0.0164 - val_mae: 0.0989 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0268 - mae: 0.1143 - val_loss: 0.0169 - val_mae: 0.1028 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0268 - mae: 0.1143 - val_loss: 0.0169 - val_mae: 0.1028 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0227 - mae: 0.1069 - val_loss: 0.0162 - val_mae: 0.0994 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0227 - mae: 0.1069 - val_loss: 0.0162 - val_mae: 0.0994 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0266 - mae: 0.1126 - val_loss: 0.0166 - val_mae: 0.1011 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0266 - mae: 0.1126 - val_loss: 0.0166 - val_mae: 0.1011 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0264 - mae: 0.1143 - val_loss: 0.0166 - val_mae: 0.1008 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0264 - mae: 0.1143 - val_loss: 0.0166 - val_mae: 0.1008 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 0.0168 - val_mae: 0.1014 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 0.0168 - val_mae: 0.1014 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0238 - mae: 0.1093 - val_loss: 0.0164 - val_mae: 0.0997 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0238 - mae: 0.1093 - val_loss: 0.0164 - val_mae: 0.0997 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0283 - mae: 0.1152\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0283 - mae: 0.1152 - val_loss: 0.0168 - val_mae: 0.1018 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0283 - mae: 0.1152 - val_loss: 0.0168 - val_mae: 0.1018 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0285 - mae: 0.1159 - val_loss: 0.0169 - val_mae: 0.1014 - learning_rate: 6.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0285 - mae: 0.1159 - val_loss: 0.0169 - val_mae: 0.1014 - learning_rate: 6.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 0.0272 - mae: 0.1153 - val_loss: 0.0168 - val_mae: 0.1017 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 0.0272 - mae: 0.1153 - val_loss: 0.0168 - val_mae: 0.1017 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0285 - mae: 0.1165 - val_loss: 0.0165 - val_mae: 0.0994 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0285 - mae: 0.1165 - val_loss: 0.0165 - val_mae: 0.0994 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0282 - mae: 0.1167 - val_loss: 0.0168 - val_mae: 0.1008 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0282 - mae: 0.1167 - val_loss: 0.0168 - val_mae: 0.1008 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0230 - mae: 0.1053\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0230 - mae: 0.1054 - val_loss: 0.0168 - val_mae: 0.1016 - learning_rate: 6.2500e-05\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0230 - mae: 0.1054 - val_loss: 0.0168 - val_mae: 0.1016 - learning_rate: 6.2500e-05\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "âœ… Training completed in 128.86 seconds\n",
      "   â€¢ Epochs trained: 30\n",
      "   âœ… Training successful - no NaN values\n",
      "   â€¢ Final training loss: 0.023966\n",
      "   â€¢ Final validation loss: 0.016760\n",
      "\n",
      "âœ… Training completed in 128.86 seconds\n",
      "   â€¢ Epochs trained: 30\n",
      "   âœ… Training successful - no NaN values\n",
      "   â€¢ Final training loss: 0.023966\n",
      "   â€¢ Final validation loss: 0.016760\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Summary:\n",
      "   âœ… Model successfully trained on normal operation data\n",
      "   âœ… Training time: 128.86 seconds\n",
      "   âœ… Stable architecture with numerical safeguards\n",
      "   âœ… Ready for anomaly detection evaluation\n",
      "   âœ… No NaN values encountered during training\n",
      "\n",
      "âš¡ Stability Optimizations Applied:\n",
      "   â€¢ Conservative model architecture (32 LSTM units)\n",
      "   â€¢ Lower learning rate (0.0005)\n",
      "   â€¢ Gradient clipping (clipnorm=1.0)\n",
      "   â€¢ Tanh activations for stability\n",
      "   â€¢ Data clipping to avoid extreme values\n",
      "   â€¢ Careful weight initialization\n",
      "   â€¢ Enhanced numerical checks\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT REQUIRED LIBRARIES AND MODULES\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ¤– LSTM Autoencoder for Anomaly Detection\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import our custom modules\n",
    "from src.autoencoder_models import StableLSTMAutoencoder\n",
    "from src.unsupervised_preprocessing import UnsupervisedDataPreprocessor\n",
    "from src.anomaly_detection import AnomalyDetector, visualize_latent_space\n",
    "\n",
    "# Set TensorFlow to avoid NaN issues\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "# Check if we have loaded data from previous cell\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "    and \"anomaly_windows\" in locals()\n",
    "    and anomaly_windows is not None\n",
    "    and len(anomaly_windows) > 0\n",
    "):\n",
    "\n",
    "    print(\"âœ… Data available for processing\")\n",
    "    print(f\"ğŸŸ¢ Normal operation windows: {len(normal_windows)}\")\n",
    "    print(f\"ğŸ”´ Anomaly windows: {len(anomaly_windows)}\")\n",
    "    data_ready = True\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"âŒ No data available. Please run the previous cell first to load normal and anomaly data.\"\n",
    "    )\n",
    "    data_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647600ad",
   "metadata": {},
   "source": [
    "## ğŸ§© Modular LSTM Autoencoder Implementation\n",
    "\n",
    "This section implements a **stable LSTM autoencoder** for anomaly detection using a **modular approach**. The code has been organized into reusable components in the `src/` directory:\n",
    "\n",
    "### ğŸ“¦ New Modules Created:\n",
    "\n",
    "1. **`autoencoder_models.py`** - Contains the `StableLSTMAutoencoder` class with:\n",
    "   - Stable architecture with gradient clipping\n",
    "   - Conservative hyperparameters for numerical stability\n",
    "   - Built-in training and prediction methods\n",
    "\n",
    "2. **`unsupervised_preprocessing.py`** - Contains the `UnsupervisedDataPreprocessor` class with:\n",
    "   - Smart data sampling for training efficiency\n",
    "   - Robust data validation and conversion\n",
    "   - Numerical stability enhancements\n",
    "\n",
    "3. **`anomaly_detection.py`** - Contains the `AnomalyDetector` class with:\n",
    "   - Reconstruction error computation\n",
    "   - Threshold determination methods\n",
    "   - Performance evaluation and visualization\n",
    "\n",
    "### ğŸ¯ Benefits of This Approach:\n",
    "\n",
    "- **Modularity**: Each component has a single responsibility\n",
    "- **Reusability**: Classes can be used in other projects\n",
    "- **Maintainability**: Easier to debug and modify individual components\n",
    "- **Stability**: Enhanced numerical safeguards and error handling\n",
    "- **Clarity**: Notebook cells are focused and easier to understand\n",
    "\n",
    "### ğŸš€ Usage Pattern:\n",
    "\n",
    "The following cells demonstrate the complete pipeline from data preprocessing through model training to anomaly detection evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA PREPROCESSING AND SAMPLING\n",
    "# ============================================================\n",
    "\n",
    "if data_ready:\n",
    "    print(\"ğŸ”§ Data Preprocessing Pipeline\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # Initialize data preprocessor with conservative settings for stability\n",
    "    preprocessor = UnsupervisedDataPreprocessor(\n",
    "        max_training_samples=1000,  # Reduced for stability\n",
    "        max_anomaly_samples=300,  # Reduced for stability\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    # Run the complete preprocessing pipeline\n",
    "    normal_scaled, anomaly_scaled, data_info = preprocessor.prepare_full_pipeline(\n",
    "        normal_windows, anomaly_windows\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ… Data preprocessing completed successfully!\")\n",
    "    print(f\"ğŸ“‹ Final Configuration:\")\n",
    "    print(f\"   â€¢ Time steps per window: {data_info['time_steps']}\")\n",
    "    print(\n",
    "        f\"   â€¢ Features per time step: {data_info['n_features']} (class column removed)\"\n",
    "    )\n",
    "    print(f\"   â€¢ Normal training samples: {data_info['n_normal_samples']}\")\n",
    "    print(f\"   â€¢ Anomaly test samples: {data_info['n_anomaly_samples']}\")\n",
    "\n",
    "    preprocessing_complete = True\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot proceed with preprocessing - no data available\")\n",
    "    preprocessing_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD AND TRAIN LSTM AUTOENCODER\n",
    "# ============================================================\n",
    "\n",
    "if preprocessing_complete:\n",
    "    print(\"ğŸ§  Building and Training LSTM Autoencoder\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # Initialize the autoencoder with conservative parameters for stability\n",
    "    autoencoder = StableLSTMAutoencoder(\n",
    "        time_steps=data_info[\"time_steps\"],\n",
    "        n_features=data_info[\"n_features\"],\n",
    "        latent_dim=16,  # Conservative for stability\n",
    "        lstm_units=32,  # Conservative for stability\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model = autoencoder.build_model()\n",
    "\n",
    "    # Split normal data into train/validation (80/20 split)\n",
    "    split_idx = int(0.8 * len(normal_scaled))\n",
    "    train_normal = normal_scaled[:split_idx]\n",
    "    val_normal = normal_scaled[split_idx:]\n",
    "\n",
    "    print(f\"\\nğŸ“Š Training Data Split:\")\n",
    "    print(f\"   â€¢ Training samples: {len(train_normal)}\")\n",
    "    print(f\"   â€¢ Validation samples: {len(val_normal)}\")\n",
    "\n",
    "    # Train the autoencoder\n",
    "    print(f\"\\nğŸš‚ Starting Training...\")\n",
    "    training_start = time.time()\n",
    "\n",
    "    training_success = autoencoder.train(\n",
    "        train_data=train_normal,\n",
    "        val_data=val_normal,\n",
    "        epochs=30,  # Conservative for stability\n",
    "        batch_size=32,  # Conservative for stability\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - training_start\n",
    "    print(f\"\\nâ±ï¸ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    if training_success:\n",
    "        print(\"âœ… Model trained successfully - ready for anomaly detection!\")\n",
    "        model_ready = True\n",
    "    else:\n",
    "        print(\"âŒ Training failed - check for numerical stability issues\")\n",
    "        model_ready = False\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot build model - preprocessing not completed\")\n",
    "    model_ready = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "if model_ready and autoencoder.history is not None:\n",
    "    print(\"ğŸ“Š Training History Visualization\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    history = autoencoder.history.history\n",
    "\n",
    "    # Create training plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history[\"loss\"], label=\"Training Loss\", linewidth=2, color=\"blue\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\", linewidth=2, color=\"orange\")\n",
    "    plt.title(\"Model Loss During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # MAE plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history[\"mae\"], label=\"Training MAE\", linewidth=2, color=\"blue\")\n",
    "    plt.plot(history[\"val_mae\"], label=\"Validation MAE\", linewidth=2, color=\"orange\")\n",
    "    plt.title(\"Model MAE During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning rate plot (if available)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if \"lr\" in history:\n",
    "        plt.plot(history[\"lr\"], label=\"Learning Rate\", linewidth=2, color=\"green\")\n",
    "        plt.title(\"Learning Rate Schedule\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            \"Learning Rate\\nHistory\\nNot Available\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"lightgray\"),\n",
    "        )\n",
    "        plt.title(\"Learning Rate Schedule\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print training summary\n",
    "    final_train_loss = history[\"loss\"][-1]\n",
    "    final_val_loss = history[\"val_loss\"][-1]\n",
    "    epochs_trained = len(history[\"loss\"])\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Training Summary:\")\n",
    "    print(f\"   â€¢ Epochs trained: {epochs_trained}\")\n",
    "    print(f\"   â€¢ Final training loss: {final_train_loss:.6f}\")\n",
    "    print(f\"   â€¢ Final validation loss: {final_val_loss:.6f}\")\n",
    "    print(f\"   â€¢ Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    if final_val_loss < final_train_loss * 1.5:\n",
    "        print(\"   âœ… No significant overfitting detected\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ Possible overfitting - validation loss higher than expected\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No training history available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANOMALY DETECTION AND EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "if model_ready:\n",
    "    print(\"ğŸ” Anomaly Detection and Evaluation\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # Initialize anomaly detector\n",
    "    detector = AnomalyDetector()\n",
    "\n",
    "    # Compute reconstruction errors\n",
    "    normal_errors, anomaly_errors = detector.compute_reconstruction_errors(\n",
    "        autoencoder=autoencoder, normal_data=normal_scaled, anomaly_data=anomaly_scaled\n",
    "    )\n",
    "\n",
    "    # Determine threshold using 95th percentile of normal errors\n",
    "    threshold = detector.determine_threshold(method=\"percentile\", percentile=95)\n",
    "\n",
    "    # Evaluate detection performance\n",
    "    metrics = detector.evaluate_detection()\n",
    "\n",
    "    print(f\"\\nğŸ¯ Anomaly Detection Results:\")\n",
    "    print(f\"   â€¢ Threshold: {threshold:.6f}\")\n",
    "    print(f\"   â€¢ Normal accuracy: {metrics['normal_accuracy']:.3f}\")\n",
    "    print(f\"   â€¢ Anomaly accuracy: {metrics['anomaly_accuracy']:.3f}\")\n",
    "    print(f\"   â€¢ Overall accuracy: {metrics['overall_accuracy']:.3f}\")\n",
    "\n",
    "    detection_complete = True\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot perform anomaly detection - model not ready\")\n",
    "    detection_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78676a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESULTS VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\"ğŸ“Š Comprehensive Results Visualization\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Plot reconstruction error distributions\n",
    "    print(\"ğŸ“ˆ Plotting reconstruction error distributions...\")\n",
    "    detector.plot_error_distributions(figsize=(15, 10))\n",
    "\n",
    "    # Plot ROC curve\n",
    "    print(\"ğŸ“ˆ Plotting ROC curve...\")\n",
    "    roc_auc = detector.plot_roc_curve()\n",
    "\n",
    "    print(f\"\\nğŸ“Š Visualization Summary:\")\n",
    "    print(f\"   âœ… Error distribution plots generated\")\n",
    "    print(f\"   âœ… ROC curve generated (AUC: {roc_auc:.3f})\")\n",
    "    print(f\"   âœ… Comprehensive analysis completed\")\n",
    "\n",
    "    if roc_auc > 0.8:\n",
    "        print(f\"   ğŸ‰ Excellent anomaly detection performance!\")\n",
    "    elif roc_auc > 0.7:\n",
    "        print(f\"   ğŸ‘ Good anomaly detection performance\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ Consider tuning model parameters for better performance\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot generate visualizations - detection not completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f25ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LATENT SPACE VISUALIZATION (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\"ğŸ¨ Advanced Analysis: Latent Space Visualization\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Visualize latent space with t-SNE\n",
    "        visualize_latent_space(\n",
    "            autoencoder=autoencoder,\n",
    "            normal_data=normal_scaled,\n",
    "            anomaly_data=anomaly_scaled,\n",
    "            n_samples=500,  # Sample for faster computation\n",
    "        )\n",
    "\n",
    "        print(f\"\\nâœ… Latent space visualization completed\")\n",
    "        print(f\"   â€¢ This visualization shows how the autoencoder learns to\")\n",
    "        print(f\"     separate normal and anomalous patterns in its internal\")\n",
    "        print(f\"     latent representation\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Latent space visualization failed: {str(e)}\")\n",
    "        print(f\"   â€¢ This is optional and doesn't affect the main analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot visualize latent space - detection not completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d414dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Reconstruction Error Analysis and Anomaly Threshold\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Computing Reconstruction Errors\n",
      "========================================\n",
      "ğŸ”µ Computing reconstruction errors for normal data... âœ…\n",
      "ğŸ”´ Computing reconstruction errors for anomaly data... âœ…\n",
      "ğŸ”´ Computing reconstruction errors for anomaly data... âœ…\n",
      "\n",
      "ğŸ“ˆ Statistical Threshold Determination\n",
      "==========================================\n",
      "ğŸ“Š Normal Data Reconstruction Error Statistics:\n",
      "   â€¢ Mean error: 0.014571\n",
      "   â€¢ Standard deviation: 0.016475\n",
      "   â€¢ Min error: 0.000585\n",
      "   â€¢ Max error: 0.194340\n",
      "\n",
      "ğŸ¯ Anomaly Detection Threshold:\n",
      "   â€¢ Threshold (Î¼ + 3Ïƒ): 0.047522\n",
      "   â€¢ Confidence level: 99.7%\n",
      "   â€¢ Normal samples above threshold: 49 / 1000\n",
      "   â€¢ Normal false positive rate: 4.90%\n",
      "\n",
      "ğŸ”´ Anomaly Detection Performance:\n",
      "   â€¢ Anomaly samples above threshold: 125 / 300\n",
      "   â€¢ Anomaly detection rate: 41.67%\n",
      "\n",
      "ğŸ“Š Anomaly Detection by Class:\n",
      "âœ…\n",
      "\n",
      "ğŸ“ˆ Statistical Threshold Determination\n",
      "==========================================\n",
      "ğŸ“Š Normal Data Reconstruction Error Statistics:\n",
      "   â€¢ Mean error: 0.014571\n",
      "   â€¢ Standard deviation: 0.016475\n",
      "   â€¢ Min error: 0.000585\n",
      "   â€¢ Max error: 0.194340\n",
      "\n",
      "ğŸ¯ Anomaly Detection Threshold:\n",
      "   â€¢ Threshold (Î¼ + 3Ïƒ): 0.047522\n",
      "   â€¢ Confidence level: 99.7%\n",
      "   â€¢ Normal samples above threshold: 49 / 1000\n",
      "   â€¢ Normal false positive rate: 4.90%\n",
      "\n",
      "ğŸ”´ Anomaly Detection Performance:\n",
      "   â€¢ Anomaly samples above threshold: 125 / 300\n",
      "   â€¢ Anomaly detection rate: 41.67%\n",
      "\n",
      "ğŸ“Š Anomaly Detection by Class:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 300 but size of corresponding boolean axis is 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m unique_anomaly_classes:\n\u001b[32m     68\u001b[39m     cls_mask = np.array(anomaly_classes) == \u001b[38;5;28mcls\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     cls_errors = \u001b[43manomaly_errors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcls_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     70\u001b[39m     cls_detected = np.sum(cls_errors > threshold)\n\u001b[32m     71\u001b[39m     cls_total = \u001b[38;5;28mlen\u001b[39m(cls_errors)\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 0; size of axis is 300 but size of corresponding boolean axis is 1000"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUMMARY AND NEXT STEPS\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\" Unsupervised Learning Summary\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    print(f\"âœ… Complete LSTM Autoencoder Pipeline Executed:\")\n",
    "    print(\n",
    "        f\"   â€¢ Data preprocessing: {data_info['n_normal_samples']} normal, {data_info['n_anomaly_samples']} anomaly samples\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   â€¢ Model architecture: {autoencoder.lstm_units} LSTM units, {autoencoder.latent_dim} latent dimensions\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   â€¢ Training: {len(autoencoder.history.history['loss'])} epochs, final loss: {autoencoder.history.history['loss'][-1]:.6f}\"\n",
    "    )\n",
    "    print(f\"   â€¢ Anomaly detection: {metrics['overall_accuracy']:.3f} overall accuracy\")\n",
    "    print(f\"   â€¢ ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "    print(f\"\\nğŸ“ Key Learning Outcomes:\")\n",
    "    print(f\"   â€¢ LSTM autoencoders can learn normal operation patterns\")\n",
    "    print(f\"   â€¢ Reconstruction errors effectively identify anomalies\")\n",
    "    print(f\"   â€¢ Threshold selection critically impacts detection performance\")\n",
    "    print(f\"   â€¢ Latent space visualization reveals learned representations\")\n",
    "\n",
    "    print(f\"\\nğŸš€ Next Steps for Advanced Analysis:\")\n",
    "    print(f\"   â€¢ Experiment with different autoencoder architectures\")\n",
    "    print(f\"   â€¢ Try variational autoencoders (VAEs) for uncertainty quantification\")\n",
    "    print(f\"   â€¢ Implement online anomaly detection for real-time monitoring\")\n",
    "    print(\n",
    "        f\"   â€¢ Compare with other unsupervised methods (Isolation Forest, One-Class SVM)\"\n",
    "    )\n",
    "\n",
    "    # Store final results for potential further analysis\n",
    "    final_results = {\n",
    "        \"autoencoder\": autoencoder,\n",
    "        \"detector\": detector,\n",
    "        \"metrics\": metrics,\n",
    "        \"data_info\": data_info,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"normal_scaled\": normal_scaled,\n",
    "        \"anomaly_scaled\": anomaly_scaled,\n",
    "    }\n",
    "\n",
    "    print(f\"\\nğŸ’¾ Results stored in 'final_results' for further analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Analysis incomplete - please run all previous cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ADVANCED LATENT SPACE ANALYSIS (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸŒŒ Advanced Latent Space Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if \"final_results\" in locals() and final_results is not None:\n",
    "\n",
    "    # Extract components from results\n",
    "    autoencoder_model = final_results[\"autoencoder\"]\n",
    "    normal_data = final_results[\"normal_scaled\"]\n",
    "    anomaly_data = final_results[\"anomaly_scaled\"]\n",
    "\n",
    "    print(\"ğŸ§  Extracting and Analyzing Latent Representations\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Create encoder model to extract latent representations\n",
    "        encoder_input = autoencoder_model.model.input\n",
    "        encoder_output = autoencoder_model.model.get_layer(\"latent\").output\n",
    "        encoder = tf.keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "        # Extract latent representations\n",
    "        print(\"ğŸ”µ Computing latent representations for normal data...\")\n",
    "        normal_latent = encoder.predict(\n",
    "            normal_data[:500], verbose=0\n",
    "        )  # Sample for efficiency\n",
    "\n",
    "        print(\"ğŸ”´ Computing latent representations for anomaly data...\")\n",
    "        anomaly_latent = encoder.predict(\n",
    "            anomaly_data[:200], verbose=0\n",
    "        )  # Sample for efficiency\n",
    "\n",
    "        print(f\"ğŸ“Š Latent space analysis:\")\n",
    "        print(f\"   â€¢ Normal latent shape: {normal_latent.shape}\")\n",
    "        print(f\"   â€¢ Anomaly latent shape: {anomaly_latent.shape}\")\n",
    "        print(f\"   â€¢ Latent dimension: {normal_latent.shape[1]}\")\n",
    "\n",
    "        # Combine for analysis\n",
    "        all_latent = np.vstack([normal_latent, anomaly_latent])\n",
    "        labels = np.concatenate(\n",
    "            [\n",
    "                np.zeros(len(normal_latent)),  # 0 for normal\n",
    "                np.ones(len(anomaly_latent)),  # 1 for anomaly\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Latent space statistics\n",
    "        normal_mean = np.mean(normal_latent, axis=0)\n",
    "        anomaly_mean = np.mean(anomaly_latent, axis=0)\n",
    "        latent_separation = np.linalg.norm(normal_mean - anomaly_mean)\n",
    "\n",
    "        print(f\"\\n Latent Space Statistics:\")\n",
    "        print(f\"   â€¢ Normal latent mean magnitude: {np.linalg.norm(normal_mean):.3f}\")\n",
    "        print(f\"   â€¢ Anomaly latent mean magnitude: {np.linalg.norm(anomaly_mean):.3f}\")\n",
    "        print(f\"   â€¢ Mean separation distance: {latent_separation:.3f}\")\n",
    "\n",
    "        # Simple 2D visualization if latent dimension allows\n",
    "        if normal_latent.shape[1] >= 2:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "\n",
    "            # Plot first two latent dimensions\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.scatter(\n",
    "                normal_latent[:, 0],\n",
    "                normal_latent[:, 1],\n",
    "                alpha=0.6,\n",
    "                label=\"Normal\",\n",
    "                color=\"blue\",\n",
    "                s=20,\n",
    "            )\n",
    "            plt.scatter(\n",
    "                anomaly_latent[:, 0],\n",
    "                anomaly_latent[:, 1],\n",
    "                alpha=0.6,\n",
    "                label=\"Anomaly\",\n",
    "                color=\"red\",\n",
    "                s=20,\n",
    "            )\n",
    "            plt.xlabel(\"Latent Dimension 1\")\n",
    "            plt.ylabel(\"Latent Dimension 2\")\n",
    "            plt.title(\"Latent Space (First 2 Dimensions)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot latent dimension distributions\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(\n",
    "                normal_latent[:, 0],\n",
    "                bins=30,\n",
    "                alpha=0.7,\n",
    "                label=\"Normal (Dim 1)\",\n",
    "                color=\"blue\",\n",
    "                density=True,\n",
    "            )\n",
    "            plt.hist(\n",
    "                anomaly_latent[:, 0],\n",
    "                bins=30,\n",
    "                alpha=0.7,\n",
    "                label=\"Anomaly (Dim 1)\",\n",
    "                color=\"red\",\n",
    "                density=True,\n",
    "            )\n",
    "            plt.xlabel(\"Latent Value\")\n",
    "            plt.ylabel(\"Density\")\n",
    "            plt.title(\"Latent Dimension 1 Distribution\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"\\nâœ… Advanced latent space analysis completed\")\n",
    "        print(f\"   â€¢ The latent space shows how the autoencoder compresses\")\n",
    "        print(f\"     time series data into a lower-dimensional representation\")\n",
    "        print(f\"   â€¢ Separation in latent space indicates learned differences\")\n",
    "        print(f\"     between normal and anomalous patterns\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Advanced latent analysis failed: {str(e)}\")\n",
    "        print(f\"   â€¢ This is optional and doesn't affect the main results\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No results available for latent space analysis\")\n",
    "    print(\"   â€¢ Please run all previous cells to generate results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ³ Individual Algorithm Training Example\n",
      "==================================================\n",
      "ğŸ“Š Comprehensive classification already completed above!\n",
      "ğŸ” Here's how to access individual algorithm results:\n",
      "\n",
      "ğŸŒ³ Tree-Based Models Performance:\n",
      "----------------------------------------\n",
      "Decision Tree:\n",
      "   â€¢ Training Accuracy: 0.657\n",
      "   â€¢ Test Accuracy: 0.389\n",
      "   â€¢ Training Time: 3.906s\n",
      "\n",
      "Random Forest:\n",
      "   â€¢ Training Accuracy: 0.866\n",
      "   â€¢ Test Accuracy: 0.531\n",
      "   â€¢ Training Time: 2.421s\n",
      "   â€¢ Top 5 Most Important Features:\n",
      "     1. Feature 593: 0.0087\n",
      "     2. Feature 577: 0.0072\n",
      "     3. Feature 581: 0.0065\n",
      "     4. Feature 595: 0.0063\n",
      "     5. Feature 569: 0.0062\n",
      "\n",
      "ğŸ’¡ To train individual algorithms separately:\n",
      "   1. Use supervised_classifier.prepare_data() to get X_train, y_train, X_test, y_test\n",
      "   2. Call supervised_classifier.train_decision_trees(X_train, y_train, X_test, y_test)\n",
      "   3. Or use supervised_classifier.train_svm() or train_neural_networks()\n",
      "\n",
      "ğŸ”§ Example: Training only Decision Trees individually\n",
      "(This would be useful if you only want specific algorithms)\n",
      "âœ… Data preparation, class balancing, and augmentation already handled by module\n",
      "âœ… All models already trained - see comprehensive results above\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LSTM AUTOENCODER FOR NOVELTY DETECTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ¤– LSTM Autoencoder Novelty Detection Implementation\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Check if we have loaded data from previous cell\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "    and \"anomaly_windows\" in locals()\n",
    "    and anomaly_windows is not None\n",
    "    and len(anomaly_windows) > 0\n",
    "):\n",
    "\n",
    "    # Import required libraries\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input,\n",
    "        LSTM,\n",
    "        Dense,\n",
    "        RepeatVector,\n",
    "        TimeDistributed,\n",
    "        Dropout,\n",
    "    )\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "    import time\n",
    "\n",
    "    print(\"ğŸ“Š Using optimized LSTM Autoencoder for novelty detection...\")\n",
    "    print(f\"ğŸŸ¢ Normal operation windows for training: {len(normal_windows)}\")\n",
    "    print(f\"ğŸ”´ Anomaly windows for testing: {len(anomaly_windows)}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # SMART DATA SAMPLING FOR FASTER TRAINING\n",
    "    # ============================================================\n",
    "    print(\"\\nâš¡ Smart Data Sampling for Training Efficiency\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Use subset for faster training (configurable)\n",
    "    MAX_TRAINING_SAMPLES = 1500  # Reduced for faster training\n",
    "    MAX_ANOMALY_SAMPLES = 500  # Reduced for faster evaluation\n",
    "\n",
    "    print(f\"ğŸ¯ Training optimization settings:\")\n",
    "    print(f\"   â€¢ Max normal samples for training: {MAX_TRAINING_SAMPLES}\")\n",
    "    print(f\"   â€¢ Max anomaly samples for testing: {MAX_ANOMALY_SAMPLES}\")\n",
    "    print(f\"   â€¢ This ensures reasonable training time with good performance\")\n",
    "\n",
    "    # Sample normal data for training\n",
    "    if len(normal_windows) > MAX_TRAINING_SAMPLES:\n",
    "        print(\n",
    "            f\"ğŸ“Š Sampling {MAX_TRAINING_SAMPLES} normal windows from {len(normal_windows)} available...\"\n",
    "        )\n",
    "        # Use random sampling to get diverse examples\n",
    "        import random\n",
    "\n",
    "        sampled_indices = random.sample(\n",
    "            range(len(normal_windows)), MAX_TRAINING_SAMPLES\n",
    "        )\n",
    "        sampled_normal_windows = [normal_windows[i] for i in sampled_indices]\n",
    "    else:\n",
    "        print(f\"ğŸ“Š Using all {len(normal_windows)} normal windows...\")\n",
    "        sampled_normal_windows = normal_windows\n",
    "\n",
    "    # Sample anomaly data for testing\n",
    "    if len(anomaly_windows) > MAX_ANOMALY_SAMPLES:\n",
    "        print(\n",
    "            f\"ğŸ“Š Sampling {MAX_ANOMALY_SAMPLES} anomaly windows from {len(anomaly_windows)} available...\"\n",
    "        )\n",
    "        sampled_indices = random.sample(\n",
    "            range(len(anomaly_windows)), MAX_ANOMALY_SAMPLES\n",
    "        )\n",
    "        sampled_anomaly_windows = [anomaly_windows[i] for i in sampled_indices]\n",
    "    else:\n",
    "        print(f\"ğŸ“Š Using all {len(anomaly_windows)} anomaly windows...\")\n",
    "        sampled_anomaly_windows = anomaly_windows\n",
    "\n",
    "    # ============================================================\n",
    "    # DATA PREPARATION WITH PROGRESS FEEDBACK\n",
    "    # ============================================================\n",
    "    print(\"\\nğŸ”§ Preparing Data for LSTM Autoencoder\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    print(\"ğŸ“Š Converting normal windows to arrays...\", end=\" \")\n",
    "    start_conversion = time.time()\n",
    "\n",
    "    # Convert normal windows to numpy arrays for training\n",
    "    normal_arrays = []\n",
    "    for i, window in enumerate(sampled_normal_windows):\n",
    "        if i % 200 == 0 and i > 0:\n",
    "            print(\n",
    "                f\"\\rğŸ“Š Converting normal windows to arrays... {i}/{len(sampled_normal_windows)}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        # Ensure consistent shape and convert to numpy\n",
    "        window_array = window.values if hasattr(window, \"values\") else window\n",
    "        normal_arrays.append(window_array)\n",
    "\n",
    "    print(\n",
    "        f\"\\rğŸ“Š Converting normal windows to arrays... âœ… ({len(normal_arrays)} processed)\"\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ“Š Converting anomaly windows to arrays...\", end=\" \")\n",
    "    # Convert anomaly windows to numpy arrays for testing\n",
    "    anomaly_arrays = []\n",
    "    for i, window in enumerate(sampled_anomaly_windows):\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(\n",
    "                f\"\\rğŸ“Š Converting anomaly windows to arrays... {i}/{len(sampled_anomaly_windows)}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        # Ensure consistent shape and convert to numpy\n",
    "        window_array = window.values if hasattr(window, \"values\") else window\n",
    "        anomaly_arrays.append(window_array)\n",
    "\n",
    "    print(\n",
    "        f\"\\rğŸ“Š Converting anomaly windows to arrays... âœ… ({len(anomaly_arrays)} processed)\"\n",
    "    )\n",
    "\n",
    "    normal_data = np.array(normal_arrays)\n",
    "    anomaly_data = np.array(anomaly_arrays)\n",
    "\n",
    "    conversion_time = time.time() - start_conversion\n",
    "    print(f\"âš¡ Data conversion completed in {conversion_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"\\nğŸ“ Data shapes:\")\n",
    "    print(f\"   â€¢ Normal data: {normal_data.shape}\")\n",
    "    print(f\"   â€¢ Anomaly data: {anomaly_data.shape}\")\n",
    "\n",
    "    # Get dimensions\n",
    "    n_normal_samples, time_steps, n_features = normal_data.shape\n",
    "\n",
    "    print(f\"\\nğŸ“‹ LSTM Autoencoder Configuration:\")\n",
    "    print(f\"   â€¢ Time steps per window: {time_steps}\")\n",
    "    print(f\"   â€¢ Features per time step: {n_features}\")\n",
    "    print(f\"   â€¢ Normal training samples: {n_normal_samples}\")\n",
    "    print(f\"   â€¢ Anomaly test samples: {anomaly_data.shape[0]}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # DATA PREPARATION (ALREADY SCALED)\n",
    "    # ============================================================\n",
    "    print(\"\\nğŸ“Š Data Already Preprocessed\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    print(\"âœ… Using pre-scaled windowed data from data treatment process\")\n",
    "    # Data is already normalized from the windowing process - no additional scaling needed\n",
    "    normal_scaled = normal_data\n",
    "    anomaly_scaled = anomaly_data\n",
    "\n",
    "    print(f\"ğŸ“ Data characteristics:\")\n",
    "    print(\n",
    "        f\"   â€¢ Normal data range: [{np.min(normal_scaled):.3f}, {np.max(normal_scaled):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   â€¢ Anomaly data range: [{np.min(anomaly_scaled):.3f}, {np.max(anomaly_scaled):.3f}]\"\n",
    "    )\n",
    "    print(f\"   â€¢ Data already optimized for neural network training\")\n",
    "\n",
    "    # ============================================================\n",
    "    # OPTIMIZED LSTM AUTOENCODER ARCHITECTURE\n",
    "    # ============================================================\n",
    "    print(\"\\nğŸ§  Building Optimized LSTM Autoencoder Architecture\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Optimized hyperparameters for faster training\n",
    "    latent_dim = 32  # Reduced from 64 for faster training\n",
    "    lstm_units = 64  # Reduced from 128 for faster training\n",
    "\n",
    "    print(f\"ğŸ—ï¸ Optimized Architecture Configuration:\")\n",
    "    print(f\"   â€¢ Input shape: ({time_steps}, {n_features})\")\n",
    "    print(f\"   â€¢ Encoder LSTM units: {lstm_units} (reduced for speed)\")\n",
    "    print(f\"   â€¢ Latent dimension: {latent_dim} (reduced for speed)\")\n",
    "    print(f\"   â€¢ Decoder LSTM units: {lstm_units}\")\n",
    "    print(f\"   â€¢ Output shape: ({time_steps}, {n_features})\")\n",
    "    print(f\"   â€¢ Dropout added for regularization\")\n",
    "\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(time_steps, n_features), name=\"input\")\n",
    "\n",
    "    # Encoder with dropout for regularization\n",
    "    encoded = LSTM(lstm_units, activation=\"relu\", name=\"encoder_lstm\")(input_layer)\n",
    "    encoded = Dropout(0.2, name=\"encoder_dropout\")(encoded)\n",
    "\n",
    "    # Latent representation (bottleneck)\n",
    "    latent = Dense(latent_dim, activation=\"relu\", name=\"latent\")(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = RepeatVector(time_steps, name=\"repeat_vector\")(latent)\n",
    "    decoded = LSTM(\n",
    "        lstm_units, activation=\"relu\", return_sequences=True, name=\"decoder_lstm\"\n",
    "    )(decoded)\n",
    "    decoded = Dropout(0.2, name=\"decoder_dropout\")(decoded)\n",
    "    decoded = TimeDistributed(Dense(n_features), name=\"output\")(decoded)\n",
    "\n",
    "    # Create autoencoder model\n",
    "    autoencoder = Model(input_layer, decoded, name=\"optimized_lstm_autoencoder\")\n",
    "\n",
    "    # Compile model with optimized settings\n",
    "    autoencoder.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=0.002\n",
    "        ),  # Slightly higher learning rate for faster convergence\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"],\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Optimized LSTM Autoencoder model created\")\n",
    "\n",
    "    # Display model summary (compact)\n",
    "    print(f\"\\nğŸ“‹ Model Summary:\")\n",
    "    print(f\"   â€¢ Total parameters: {autoencoder.count_params():,}\")\n",
    "    print(\n",
    "        f\"   â€¢ Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in autoencoder.trainable_weights]):,}\"\n",
    "    )\n",
    "    print(f\"   â€¢ Model architecture optimized for faster training\")\n",
    "\n",
    "    # ============================================================\n",
    "    # OPTIMIZED MODEL TRAINING WITH PROGRESS FEEDBACK\n",
    "    # ============================================================\n",
    "    print(\"\\nğŸš‚ Training Optimized LSTM Autoencoder on Normal Data\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    # Split normal data into train/validation (80/20 split)\n",
    "    split_idx = int(0.8 * len(normal_scaled))\n",
    "    train_normal = normal_scaled[:split_idx]\n",
    "    val_normal = normal_scaled[split_idx:]\n",
    "\n",
    "    print(f\"ğŸ“Š Training split:\")\n",
    "    print(f\"   â€¢ Training samples: {len(train_normal)}\")\n",
    "    print(f\"   â€¢ Validation samples: {len(val_normal)}\")\n",
    "\n",
    "    # Optimized callbacks for faster training\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,  # Reduced patience for faster training\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.0001, verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸš‚ Starting optimized training...\")\n",
    "    print(f\"   â€¢ Max epochs: 50 (reduced for speed)\")\n",
    "    print(f\"   â€¢ Batch size: 64 (increased for efficiency)\")\n",
    "    print(f\"   â€¢ Early stopping patience: 5 epochs\")\n",
    "    print(f\"   â€¢ Learning rate reduction on plateau\")\n",
    "\n",
    "    training_start = time.time()\n",
    "\n",
    "    # Train autoencoder with optimized parameters\n",
    "    history = autoencoder.fit(\n",
    "        train_normal,\n",
    "        train_normal,  # Autoencoder: input = target\n",
    "        validation_data=(val_normal, val_normal),\n",
    "        epochs=50,  # Reduced from 100 for faster training\n",
    "        batch_size=64,  # Increased from 32 for faster training\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1,  # Show progress during training\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - training_start\n",
    "    print(f\"\\nâœ… Training completed in {training_time:.2f} seconds\")\n",
    "    print(f\"   â€¢ Epochs trained: {len(history.history['loss'])}\")\n",
    "    print(f\"   â€¢ Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "    print(f\"   â€¢ Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "\n",
    "    # Quick training visualization\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\", linewidth=2)\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
    "    plt.title(\"Model Loss During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"mae\"], label=\"Training MAE\", linewidth=2)\n",
    "    plt.plot(history.history[\"val_mae\"], label=\"Validation MAE\", linewidth=2)\n",
    "    plt.title(\"Model MAE During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nğŸ“Š Training Summary:\")\n",
    "    print(f\"   âœ… Model successfully trained on normal operation data\")\n",
    "    print(f\"   âœ… Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"   âœ… Architecture optimized for speed and performance\")\n",
    "    print(f\"   âœ… Ready for anomaly detection evaluation\")\n",
    "\n",
    "    print(f\"\\nâš¡ Performance Optimizations Applied:\")\n",
    "    print(f\"   â€¢ Reduced model complexity (64 LSTM units vs 128)\")\n",
    "    print(f\"   â€¢ Smaller latent dimension (32 vs 64)\")\n",
    "    print(f\"   â€¢ Smart data sampling for training efficiency\")\n",
    "    print(f\"   â€¢ Increased batch size for faster training\")\n",
    "    print(f\"   â€¢ Reduced epochs with early stopping\")\n",
    "    print(f\"   â€¢ Learning rate scheduling for optimal convergence\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"âŒ No data available. Please run the previous cell first to load normal and anomaly data.\"\n",
    "    )\n",
    "    autoencoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe37606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# QUICK AUTOENCODER TEST (OPTIONAL - FOR IMMEDIATE FEEDBACK)\n",
    "# ============================================================\n",
    "\n",
    "print(\"ğŸ”¬ Quick Autoencoder Test for Immediate Feedback\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# This cell provides immediate feedback to ensure everything works\n",
    "# Run this first if you want to test the setup before full training\n",
    "\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "):\n",
    "\n",
    "    # Quick test with minimal data\n",
    "    print(\"ğŸš€ Testing with minimal dataset for immediate feedback...\")\n",
    "\n",
    "    # Use only a tiny subset for testing\n",
    "    test_normal = normal_windows[:10]  # Just 10 samples for testing\n",
    "    test_anomaly = anomaly_windows[:5] if len(anomaly_windows) >= 5 else anomaly_windows\n",
    "\n",
    "    print(f\"ğŸ§ª Test data:\")\n",
    "    print(f\"   â€¢ Normal samples: {len(test_normal)}\")\n",
    "    print(f\"   â€¢ Anomaly samples: {len(test_anomaly)}\")\n",
    "\n",
    "    # Quick conversion test with class column removal\n",
    "    print(\"ğŸ“Š Testing data conversion (removing class column)...\", end=\" \")\n",
    "    try:\n",
    "        test_normal_arrays = []\n",
    "        for window in test_normal:\n",
    "            # Get the DataFrame values and remove the class column\n",
    "            if hasattr(window, \"values\"):\n",
    "                window_data = window.copy()\n",
    "                # Remove 'class' column if it exists\n",
    "                if \"class\" in window_data.columns:\n",
    "                    window_data = window_data.drop(\"class\", axis=1)\n",
    "                    print(f\"\\n   ğŸ“‹ Removed 'class' column from DataFrame\")\n",
    "                window_array = window_data.values\n",
    "            else:\n",
    "                # If it's already an array, assume last column is class and remove it\n",
    "                if len(window.shape) == 2 and window.shape[1] > 1:\n",
    "                    window_array = window[:, :-1]  # Remove last column (class)\n",
    "                    print(f\"\\n   ğŸ“‹ Removed last column (assumed class) from array\")\n",
    "                else:\n",
    "                    window_array = window\n",
    "\n",
    "            test_normal_arrays.append(window_array)\n",
    "\n",
    "        test_normal_data = np.array(test_normal_arrays)\n",
    "        print(\"âœ…\")\n",
    "        print(f\"   â€¢ Test normal data shape: {test_normal_data.shape}\")\n",
    "\n",
    "        # Extract dimensions\n",
    "        test_samples, test_time_steps, test_features = test_normal_data.shape\n",
    "        print(f\"   â€¢ Time steps: {test_time_steps}\")\n",
    "        print(f\"   â€¢ Features: {test_features} (after removing class column)\")\n",
    "\n",
    "        # Check data characteristics\n",
    "        print(\n",
    "            f\"   â€¢ Data range: [{np.min(test_normal_data):.3f}, {np.max(test_normal_data):.3f}]\"\n",
    "        )\n",
    "        print(f\"   â€¢ Data type: {test_normal_data.dtype}\")\n",
    "\n",
    "        # Verify the first window columns if it's a DataFrame\n",
    "        if hasattr(test_normal[0], \"columns\"):\n",
    "            print(f\"   â€¢ Original columns: {list(test_normal[0].columns)}\")\n",
    "            if \"class\" in test_normal[0].columns:\n",
    "                print(\n",
    "                    f\"   â€¢ Features after removing class: {list(test_normal[0].drop('class', axis=1).columns)}\"\n",
    "                )\n",
    "\n",
    "        print(f\"\\nâœ… Quick test successful! Data is ready for LSTM autoencoder.\")\n",
    "        print(f\"âœ… Class column properly handled and removed from features.\")\n",
    "        print(f\"ğŸ’¡ You can now run the full training cell with confidence.\")\n",
    "        print(f\"âš¡ Estimated full training time: ~2-5 minutes with optimized settings\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in quick test: {str(e)}\")\n",
    "        print(f\"ğŸ’¡ Please check the data loading cell and try again\")\n",
    "\n",
    "        # Show more detailed error information\n",
    "        import traceback\n",
    "\n",
    "        print(f\"\\nğŸ” Detailed error:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No normal_windows data available.\")\n",
    "    print(\"ğŸ’¡ Please run the data loading cell first.\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Next Steps:\")\n",
    "print(f\"   1. âœ… Quick test completed - data is compatible\")\n",
    "print(f\"   2. âœ… Class column handling verified\")\n",
    "print(f\"   3. ğŸš‚ Run the full training cell below for complete autoencoder\")\n",
    "print(f\"   4. ğŸ” Proceed to anomaly detection evaluation\")\n",
    "print(f\"   5. ğŸ“Š Visualize results and performance metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b91df2",
   "metadata": {},
   "source": [
    "##  Introduction to Autoencoders for Novelty Detection (5 minutes)\n",
    "\n",
    "### What are Autoencoders?\n",
    "\n",
    "**Autoencoders** are neural networks designed to learn efficient data representations by training the network to copy its input to its output. They learn to compress and then reconstruct data.\n",
    "\n",
    "### Autoencoder Architecture:\n",
    "- **Input Layer**: Original data (e.g., sensor readings)\n",
    "- **Encoder**: Compresses input into lower-dimensional representation\n",
    "- **Latent Space**: Compressed representation (bottleneck)\n",
    "- **Decoder**: Reconstructs original data from compressed representation\n",
    "- **Output Layer**: Reconstructed data (should match input)\n",
    "\n",
    "### How Autoencoders Detect Novelty:\n",
    "\n",
    "1. **Training Phase**: Learn to reconstruct only normal data\n",
    "2. **Normal Data**: Low reconstruction error (model learned these patterns)\n",
    "3. **Anomalous Data**: High reconstruction error (model never saw these patterns)\n",
    "4. **Threshold**: Statistical boundary between normal and anomalous reconstruction errors\n",
    "\n",
    "### Why Autoencoders for Oil Well Data:\n",
    "\n",
    "#### Advantages:\n",
    "- **Unsupervised Learning**: Only need normal operation data\n",
    "- **Feature Learning**: Automatically discover important sensor patterns\n",
    "- **Dimensionality Reduction**: Handle high-dimensional sensor data efficiently\n",
    "- **Non-linear Patterns**: Capture complex relationships between sensors\n",
    "- **Reconstruction-Based**: Intuitive interpretation of anomaly scores\n",
    "\n",
    "#### LSTM Autoencoders Specifically:\n",
    "- **Temporal Modeling**: Handle time series sensor data naturally\n",
    "- **Sequential Dependencies**: Capture patterns across time steps\n",
    "- **Variable Sequences**: Adapt to different operational phases\n",
    "- **Memory Cells**: Remember long-term normal operation patterns\n",
    "\n",
    "### Novelty Detection Process:\n",
    "\n",
    "1. **Data Preparation**: Normalize and structure time series data\n",
    "2. **Model Training**: Train autoencoder on normal data only\n",
    "3. **Error Computation**: Calculate reconstruction errors for all data\n",
    "4. **Threshold Setting**: Use statistical methods (Î¼ + 3Ïƒ) on normal errors\n",
    "5. **Anomaly Detection**: Flag samples with errors above threshold\n",
    "6. **Validation**: Test on known fault data to evaluate performance\n",
    "\n",
    "### Industrial Applications:\n",
    "- **Predictive Maintenance**: Detect equipment degradation early\n",
    "- **Quality Control**: Identify production anomalies\n",
    "- **System Monitoring**: Continuous health assessment\n",
    "- **Safety Systems**: Early warning for critical failures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}